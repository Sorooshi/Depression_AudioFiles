{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I495_HFnGkGI"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXXfZZQSGjT9",
        "outputId": "50f00a4a-ea42-4df6-c094-720816106aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_forecasting\n",
            "  Downloading pytorch_forecasting-1.0.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.80 (from pytorch_forecasting)\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning<3.0.0,>=2.0.0 (from pytorch_forecasting)\n",
            "  Downloading lightning-2.0.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (3.7.1)\n",
            "Collecting optuna<4.0.0,>=3.1.0 (from pytorch_forecasting)\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<=3.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (1.5.3)\n",
            "Collecting pytorch-optimizer<3.0.0,>=2.5.1 (from pytorch_forecasting)\n",
            "  Downloading pytorch_optimizer-2.9.1-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (1.10.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (0.13.5)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (2.0.1+cu118)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch_forecasting) (1.10.7)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.80->pytorch_forecasting)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (3.1.2)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (6.0)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (8.1.3)\n",
            "Collecting croniter<1.4.0,>=1.3.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading croniter-1.3.15-py2.py3-none-any.whl (19 kB)\n",
            "Collecting dateutils<2.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.80 (from pytorch_forecasting)\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2023.4.0)\n",
            "Collecting inquirer<5.0,>=2.10.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting lightning-cloud>=0.5.34 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading lightning_cloud-0.5.36-py3-none-any.whl (562 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (23.1)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (5.9.5)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.27.1)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (13.3.4)\n",
            "Collecting starsessions<2.0,>=1.2.1 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting torchmetrics<2.0,>=0.7.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (4.65.0)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.26.15)\n",
            "Collecting uvicorn<2.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.5.1)\n",
            "Collecting websockets<12.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m828.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (3.6.2)\n",
            "Collecting alembic>=1.5.0 (from optuna<4.0.0,>=3.1.0->pytorch_forecasting)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna<4.0.0,>=3.1.0->pytorch_forecasting)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna<4.0.0,>=3.1.0->pytorch_forecasting)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch_forecasting) (2.0.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch_forecasting) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch_forecasting) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch_forecasting) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch_forecasting) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch_forecasting) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0.0,>=2.0.0->pytorch_forecasting) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0.0,>=2.0.0->pytorch_forecasting) (16.0.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch_forecasting) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch_forecasting) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch_forecasting) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch_forecasting) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch_forecasting) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch_forecasting) (3.0.9)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pytorch_forecasting) (0.5.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna<4.0.0,>=3.1.0->pytorch_forecasting)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.4.1)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec<2024.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.1.2)\n",
            "Collecting pyjwt (from lightning-cloud>=0.5.34->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting python-multipart (from lightning-cloud>=0.5.34->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.14.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna<4.0.0,>=3.1.0->pytorch_forecasting) (2.0.2)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.1.2)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->pytorch_forecasting) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (0.2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (0.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (67.7.2)\n",
            "Installing collected packages: python-editor, websockets, readchar, python-multipart, pyjwt, ordered-set, multidict, Mako, lightning-utilities, h11, frozenlist, colorlog, cmaes, blessed, async-timeout, yarl, uvicorn, starlette, inquirer, deepdiff, dateutils, croniter, arrow, alembic, aiosignal, starsessions, optuna, fastapi, aiohttp, lightning-cloud, torchmetrics, pytorch-lightning, pytorch-optimizer, lightning, pytorch_forecasting\n",
            "Successfully installed Mako-1.2.4 aiohttp-3.8.4 aiosignal-1.3.1 alembic-1.11.1 arrow-1.2.3 async-timeout-4.0.2 blessed-1.20.0 cmaes-0.9.1 colorlog-6.7.0 croniter-1.3.15 dateutils-0.6.12 deepdiff-6.3.0 fastapi-0.88.0 frozenlist-1.3.3 h11-0.14.0 inquirer-3.1.3 lightning-2.0.2 lightning-cloud-0.5.36 lightning-utilities-0.8.0 multidict-6.0.4 optuna-3.1.1 ordered-set-4.1.0 pyjwt-2.7.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.2 pytorch-optimizer-2.9.1 pytorch_forecasting-1.0.0 readchar-4.0.5 starlette-0.22.0 starsessions-1.3.0 torchmetrics-0.11.4 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dtaidistance\n",
            "  Downloading dtaidistance-2.3.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dtaidistance) (1.22.4)\n",
            "Installing collected packages: dtaidistance\n",
            "Successfully installed dtaidistance-2.3.10\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install pytorch_forecasting\n",
        "!pip install dtaidistance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaXicZPcGkyH"
      },
      "source": [
        "# Main part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mkteus6rboLc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa as lb\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_COWnqST9qwh",
        "outputId": "1acaf5ba-489b-4953-aa96-02b939e51241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kkkrJwi573Ty"
      },
      "outputs": [],
      "source": [
        "#Global Sample Rate\n",
        "# SR = 22000\n",
        "SR = 8000\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "DRIVE_PATH = 'drive/MyDrive/psychiatric.disorders.ML'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TETnemGVbr_F"
      },
      "outputs": [],
      "source": [
        "participants = pd.read_excel(os.path.join(DRIVE_PATH, 'PsychiatricDiscourse_participant.data.xlsx'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WNFZU5pLdAre"
      },
      "outputs": [],
      "source": [
        "# depression_only\n",
        "depression_only = participants.loc[\n",
        "    (participants['thought.disorder.symptoms'] == 0.) &\n",
        "    (participants['depression.symptoms'] != 0.)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XReJrofcdIE3"
      },
      "outputs": [],
      "source": [
        "control_group = participants.loc[\n",
        "    (participants['depression.symptoms'] == 0.) &\n",
        "    (participants['thought.disorder.symptoms'] == 0.)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fTSHu-5VdonY"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([depression_only, control_group])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1F-H4Hc-8AbG"
      },
      "outputs": [],
      "source": [
        "def get_patient_audio(row, data_folder=os.path.join(DRIVE_PATH, 'wav files'), return_uncomplete=False):\n",
        "    key = row.ID\n",
        "    audio_files = []\n",
        "    for filename in os.listdir(data_folder):\n",
        "        if filename.find(key) != -1:\n",
        "            audio_files.append(filename)\n",
        "    return audio_files\n",
        "\n",
        "df['audio'] = df.apply(get_patient_audio, axis=1)\n",
        "\n",
        "# exclude patients with num of recordings other than 3\n",
        "df = df[df.audio.apply(len) == 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Yx0KDUnr9PHT",
        "outputId": "e599a2cd-b01a-4bfd-e6c8-8c999bf13f84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/psychiatric.disorders.ML/wav files'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "os.path.join(DRIVE_PATH, 'wav files')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cm9lq_STIbK7"
      },
      "outputs": [],
      "source": [
        "task_mapping = {\n",
        "    'narrative': ['sportsman', 'adventure', 'winterday'], \n",
        "    'story': ['present', 'trip', 'party'], \n",
        "    'instruction': ['chair', 'table', 'bench']\n",
        "}\n",
        "\n",
        "def get_domain_audio(row, domain):\n",
        "    files = []\n",
        "    for topic in task_mapping[domain]:\n",
        "        for file_name in row.audio:\n",
        "            if file_name.find(topic) != -1:\n",
        "                files.append(file_name)\n",
        "                \n",
        "    if len(files) > 1:\n",
        "        print(files)\n",
        "    # assert len(files) < 2\n",
        "    return files[0] if len(files) else None\n",
        "    \n",
        "    \n",
        "    \n",
        "for domain in task_mapping:\n",
        "    df[f'audio.{domain}'] = df.apply(get_domain_audio, axis=1, domain=domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "2f0RKui0MFZ2",
        "outputId": "3191a6fc-9619-40f3-e0cf-1249db48f2b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID    group                        diagnosis     sex   age  \\\n",
              "0   PD-001  patient             schizotypal.disorder  female  19.0   \n",
              "1   PD-002  patient       bipolar.affective.disorder  female  26.0   \n",
              "3   PD-004  patient  borderline.personality.disorder  female  16.0   \n",
              "7   PD-008  patient       bipolar.affective.disorder  female  19.0   \n",
              "12  PD-013  patient    recurrent.depressive.disorder  female  20.0   \n",
              "\n",
              "      education.level  education.years  depression.symptoms  \\\n",
              "0           secondary               11                    1   \n",
              "1              higher               17                    1   \n",
              "3           secondary                9                    1   \n",
              "7   higher.unfinished               12                    1   \n",
              "12  higher.unfinished               12                    1   \n",
              "\n",
              "    thought.disorder.symptoms  \\\n",
              "0                           0   \n",
              "1                           0   \n",
              "3                           0   \n",
              "7                           0   \n",
              "12                          0   \n",
              "\n",
              "                                                audio  \\\n",
              "0   [PD-001-pers-1-present.wav, PD-001-instr-1-cha...   \n",
              "1   [PD-002-pers-1-present.wav, PD-002-instr-1-cha...   \n",
              "3   [PD-004-pic-1-adventure.wav, PD-004-pers-1-pre...   \n",
              "7   [PD-008-instr-1-chair.wav, PD-008-pic-1-advent...   \n",
              "12  [PD-013-pic-1-sportsman.wav, PD-013-pers-1-pre...   \n",
              "\n",
              "               audio.narrative                audio.story  \\\n",
              "0   PD-001-pic-1-sportsman.wav  PD-001-pers-1-present.wav   \n",
              "1   PD-002-pic-1-adventure.wav  PD-002-pers-1-present.wav   \n",
              "3   PD-004-pic-1-adventure.wav  PD-004-pers-1-present.wav   \n",
              "7   PD-008-pic-1-adventure.wav  PD-008-pers-1-present.wav   \n",
              "12  PD-013-pic-1-sportsman.wav  PD-013-pers-1-present.wav   \n",
              "\n",
              "           audio.instruction  \n",
              "0   PD-001-instr-1-chair.wav  \n",
              "1   PD-002-instr-1-chair.wav  \n",
              "3   PD-004-instr-1-chair.wav  \n",
              "7   PD-008-instr-1-chair.wav  \n",
              "12  PD-013-instr-1-chair.wav  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-279a24ad-ecb6-4316-b97f-0f4b6a336b0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>group</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>education.level</th>\n",
              "      <th>education.years</th>\n",
              "      <th>depression.symptoms</th>\n",
              "      <th>thought.disorder.symptoms</th>\n",
              "      <th>audio</th>\n",
              "      <th>audio.narrative</th>\n",
              "      <th>audio.story</th>\n",
              "      <th>audio.instruction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PD-001</td>\n",
              "      <td>patient</td>\n",
              "      <td>schizotypal.disorder</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>secondary</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[PD-001-pers-1-present.wav, PD-001-instr-1-cha...</td>\n",
              "      <td>PD-001-pic-1-sportsman.wav</td>\n",
              "      <td>PD-001-pers-1-present.wav</td>\n",
              "      <td>PD-001-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PD-002</td>\n",
              "      <td>patient</td>\n",
              "      <td>bipolar.affective.disorder</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>higher</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[PD-002-pers-1-present.wav, PD-002-instr-1-cha...</td>\n",
              "      <td>PD-002-pic-1-adventure.wav</td>\n",
              "      <td>PD-002-pers-1-present.wav</td>\n",
              "      <td>PD-002-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PD-004</td>\n",
              "      <td>patient</td>\n",
              "      <td>borderline.personality.disorder</td>\n",
              "      <td>female</td>\n",
              "      <td>16.0</td>\n",
              "      <td>secondary</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[PD-004-pic-1-adventure.wav, PD-004-pers-1-pre...</td>\n",
              "      <td>PD-004-pic-1-adventure.wav</td>\n",
              "      <td>PD-004-pers-1-present.wav</td>\n",
              "      <td>PD-004-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PD-008</td>\n",
              "      <td>patient</td>\n",
              "      <td>bipolar.affective.disorder</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>higher.unfinished</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[PD-008-instr-1-chair.wav, PD-008-pic-1-advent...</td>\n",
              "      <td>PD-008-pic-1-adventure.wav</td>\n",
              "      <td>PD-008-pers-1-present.wav</td>\n",
              "      <td>PD-008-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PD-013</td>\n",
              "      <td>patient</td>\n",
              "      <td>recurrent.depressive.disorder</td>\n",
              "      <td>female</td>\n",
              "      <td>20.0</td>\n",
              "      <td>higher.unfinished</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[PD-013-pic-1-sportsman.wav, PD-013-pers-1-pre...</td>\n",
              "      <td>PD-013-pic-1-sportsman.wav</td>\n",
              "      <td>PD-013-pers-1-present.wav</td>\n",
              "      <td>PD-013-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-279a24ad-ecb6-4316-b97f-0f4b6a336b0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-279a24ad-ecb6-4316-b97f-0f4b6a336b0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-279a24ad-ecb6-4316-b97f-0f4b6a336b0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXLx39MLNJ5s",
        "outputId": "a71a58de-de6e-4fd4-8d08-843e7e517e23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    142\n",
              "1     62\n",
              "2     22\n",
              "3     10\n",
              "Name: depression.symptoms, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df['depression.symptoms'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4i2dcQVjMoVN"
      },
      "outputs": [],
      "source": [
        "#80% training data and 20% test data. Split so that test data will include all types of depression severity\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, train_size = 0.8, random_state = 42)\n",
        "\n",
        "for (train_index, test_index) in sss.split(df, df['depression.symptoms']):\n",
        "  train_df = df.iloc[train_index]\n",
        "  test_df = df.iloc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "qP3PaEwHOWAS",
        "outputId": "9958953c-0e1f-4e85-e6ba-58ba8e59125e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID    group                      diagnosis     sex   age  \\\n",
              "189  PN-075  control                            NaN    male  23.0   \n",
              "32   PD-034  patient     bipolar.affective.disorder  female  20.0   \n",
              "259  PN-306  control                            NaN    male  53.0   \n",
              "179  PN-054  control                            NaN  female  24.0   \n",
              "84   PD-089  patient  recurrent.depressive.disorder  female  17.0   \n",
              "\n",
              "           education.level  education.years  depression.symptoms  \\\n",
              "189             vocational               14                    2   \n",
              "32       higher.unfinished               13                    0   \n",
              "259                 higher               20                    0   \n",
              "179                 higher               17                    2   \n",
              "84   vocational.unfinished               10                    0   \n",
              "\n",
              "     thought.disorder.symptoms  \\\n",
              "189                          0   \n",
              "32                           0   \n",
              "259                          0   \n",
              "179                          0   \n",
              "84                           0   \n",
              "\n",
              "                                                 audio  \\\n",
              "189  [PN-075-instr-1-table.wav, PN-075-pers-1-trip....   \n",
              "32   [PD-034-instr-1-chair.wav, PD-034-pic-1-advent...   \n",
              "259  [PN-306-instr-1-bench.wav, PN-306-pic-1-winter...   \n",
              "179  [PN-054-pers-1-party.wav, PN-054-instr-1-chair...   \n",
              "84   [PD-089-pers-1-present.wav, PD-089-instr-1-cha...   \n",
              "\n",
              "                audio.narrative                audio.story  \\\n",
              "189  PN-075-pic-1-adventure.wav     PN-075-pers-1-trip.wav   \n",
              "32   PD-034-pic-1-adventure.wav  PD-034-pers-1-present.wav   \n",
              "259  PN-306-pic-1-winterday.wav    PN-306-pers-1-party.wav   \n",
              "179  PN-054-pic-1-adventure.wav    PN-054-pers-1-party.wav   \n",
              "84   PD-089-pic-1-adventure.wav  PD-089-pers-1-present.wav   \n",
              "\n",
              "            audio.instruction  \n",
              "189  PN-075-instr-1-table.wav  \n",
              "32   PD-034-instr-1-chair.wav  \n",
              "259  PN-306-instr-1-bench.wav  \n",
              "179  PN-054-instr-1-chair.wav  \n",
              "84   PD-089-instr-1-chair.wav  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0649c682-3c9a-4ca5-905b-650c32f2cc25\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>group</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>education.level</th>\n",
              "      <th>education.years</th>\n",
              "      <th>depression.symptoms</th>\n",
              "      <th>thought.disorder.symptoms</th>\n",
              "      <th>audio</th>\n",
              "      <th>audio.narrative</th>\n",
              "      <th>audio.story</th>\n",
              "      <th>audio.instruction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>PN-075</td>\n",
              "      <td>control</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "      <td>23.0</td>\n",
              "      <td>vocational</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[PN-075-instr-1-table.wav, PN-075-pers-1-trip....</td>\n",
              "      <td>PN-075-pic-1-adventure.wav</td>\n",
              "      <td>PN-075-pers-1-trip.wav</td>\n",
              "      <td>PN-075-instr-1-table.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>PD-034</td>\n",
              "      <td>patient</td>\n",
              "      <td>bipolar.affective.disorder</td>\n",
              "      <td>female</td>\n",
              "      <td>20.0</td>\n",
              "      <td>higher.unfinished</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[PD-034-instr-1-chair.wav, PD-034-pic-1-advent...</td>\n",
              "      <td>PD-034-pic-1-adventure.wav</td>\n",
              "      <td>PD-034-pers-1-present.wav</td>\n",
              "      <td>PD-034-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>PN-306</td>\n",
              "      <td>control</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "      <td>53.0</td>\n",
              "      <td>higher</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[PN-306-instr-1-bench.wav, PN-306-pic-1-winter...</td>\n",
              "      <td>PN-306-pic-1-winterday.wav</td>\n",
              "      <td>PN-306-pers-1-party.wav</td>\n",
              "      <td>PN-306-instr-1-bench.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>PN-054</td>\n",
              "      <td>control</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>24.0</td>\n",
              "      <td>higher</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[PN-054-pers-1-party.wav, PN-054-instr-1-chair...</td>\n",
              "      <td>PN-054-pic-1-adventure.wav</td>\n",
              "      <td>PN-054-pers-1-party.wav</td>\n",
              "      <td>PN-054-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>PD-089</td>\n",
              "      <td>patient</td>\n",
              "      <td>recurrent.depressive.disorder</td>\n",
              "      <td>female</td>\n",
              "      <td>17.0</td>\n",
              "      <td>vocational.unfinished</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[PD-089-pers-1-present.wav, PD-089-instr-1-cha...</td>\n",
              "      <td>PD-089-pic-1-adventure.wav</td>\n",
              "      <td>PD-089-pers-1-present.wav</td>\n",
              "      <td>PD-089-instr-1-chair.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0649c682-3c9a-4ca5-905b-650c32f2cc25')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0649c682-3c9a-4ca5-905b-650c32f2cc25 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0649c682-3c9a-4ca5-905b-650c32f2cc25');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJAP5TrUPxnl",
        "outputId": "31e5060d-485b-4303-a12e-40ce39f91dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnPGSCIcNKf3"
      },
      "source": [
        "## Data and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si57LIsWNMve",
        "outputId": "250dfbf1-2073-4813-c215-f8107099db91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# from tqdm import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "import pytorch_forecasting as ptf\n",
        "import torch\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data import NaNLabelEncoder\n",
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.callbacks import EarlyStopping\n",
        "from pytorch_forecasting.metrics import RMSE, MultivariateNormalDistributionLoss, QuantileLoss\n",
        "from dtaidistance import dtw\n",
        "from itertools import product\n",
        "import sklearn.metrics as skm\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "pl.seed_everything(42)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yVRcrEzb14m8"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DuyimcsvL-Dc"
      },
      "outputs": [],
      "source": [
        "BASE_LEN = 83\n",
        "BATCH_SIZE = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BwdyraSmNRYw"
      },
      "outputs": [],
      "source": [
        "def cut_recordings(data, audio_dur, cutoff_len, min_len = 0):\n",
        "  res = []\n",
        "  cnt = 1\n",
        "  res.append(data[:int(cutoff_len * SR)])\n",
        "  audio_dur -= cutoff_len\n",
        "\n",
        "  while(audio_dur > min_len and cnt < 100):\n",
        "    res.append(data[int(cutoff_len * SR)*cnt:int(cutoff_len * SR)*(cnt+1)])\n",
        "    audio_dur -= cutoff_len\n",
        "    cnt += 1\n",
        "\n",
        "  return res\n",
        "\n",
        "\n",
        "def pad_ts(data, max_dur):\n",
        "  for i in range(len(data)):\n",
        "      if (len(data[i]) < max_dur):\n",
        "        data[i] = np.pad(data[i], (max_dur - len(data[i]), 0), 'constant', constant_values=(0,))\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def load_and_preprocess(files, data_folder, cutoff_len = None, min_len=0):\n",
        "  audio_ts = []\n",
        "\n",
        "  for filename in files:\n",
        "      signal, sr = lb.load(os.path.join(data_folder, filename), sr=SR)\n",
        "      signal, _ = lb.effects.trim(signal, top_db=40)\n",
        "      audio_ts.append(signal)\n",
        "\n",
        "\n",
        "  for i in range(len(audio_ts)):\n",
        "    audio_dur = len(audio_ts[i]) / SR\n",
        "\n",
        "    audio_ts[i] = cut_recordings(data = audio_ts[i], audio_dur = audio_dur, \n",
        "                                 cutoff_len = cutoff_len, min_len = min_len)\n",
        "    audio_ts[i] = pad_ts(audio_ts[i], cutoff_len*SR)\n",
        "\n",
        "  upd_df = pd.DataFrame(columns=[f'observations', 'time_idx', 'group'])\n",
        "  audio_len = len(audio_ts[0][0])\n",
        "\n",
        "\n",
        "  for i in range(len(audio_ts)):\n",
        "    for j in range(len(audio_ts[i])):\n",
        "      if j >= 10:\n",
        "        tmp_df = pd.DataFrame({'observations':audio_ts[i][j], 'time_idx' : np.arange(audio_len), 'group':[f'{j}_' + files.iloc[i]] * audio_len})\n",
        "      else:\n",
        "        tmp_df = pd.DataFrame({'observations':audio_ts[i][j], 'time_idx' : np.arange(audio_len), 'group':[f'0{j}_' + files.iloc[i]] * audio_len})\n",
        "\n",
        "      upd_df = pd.concat([upd_df, tmp_df], axis=0, ignore_index=True)\n",
        "\n",
        "  upd_df['time_idx'] = upd_df['time_idx'].astype(int)\n",
        "\n",
        "  return upd_df\n",
        "\n",
        "\n",
        "def create_timeSeriesDataSet(df, encoder_len = 60, prediction_len = 60):\n",
        "  # Replace \".\" with \"_\"\n",
        "  df.columns = [col.replace(\".\", \"_\") for col in df.columns]\n",
        "\n",
        "  # Define the TimeSeriesDataSet object\n",
        "  training_cutoff = df[\"time_idx\"].max() - prediction_len\n",
        "\n",
        "  training = TimeSeriesDataSet(\n",
        "      data=df.loc[lambda x: x.time_idx <= training_cutoff],\n",
        "      time_idx=\"time_idx\",\n",
        "      target = \"observations\",\n",
        "      group_ids= [\"group\"],\n",
        "      max_encoder_length=encoder_len,\n",
        "      max_prediction_length=prediction_len,\n",
        "      time_varying_unknown_reals=[\"observations\"],\n",
        "      time_varying_known_reals=[\"time_idx\"],\n",
        "  )\n",
        "\n",
        "  validation = TimeSeriesDataSet.from_dataset(training, df, min_prediction_idx=training_cutoff+1)\n",
        "  # validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
        "  return (training, validation)\n",
        "\n",
        "\n",
        "def create_timeSeriesDataSet_test(df, encoder_len = 60, prediction_len = 60):\n",
        "  # Replace \".\" with \"_\"\n",
        "  df.columns = [col.replace(\".\", \"_\") for col in df.columns]\n",
        "\n",
        "  # Define the TimeSeriesDataSet object\n",
        "  training_cutoff = df[\"time_idx\"].max() - prediction_len\n",
        "\n",
        "  test = TimeSeriesDataSet(\n",
        "      data=df,\n",
        "      time_idx=\"time_idx\",\n",
        "      target = \"observations\",\n",
        "      group_ids= [\"group\"],\n",
        "      max_encoder_length=encoder_len,\n",
        "      max_prediction_length=prediction_len,\n",
        "      time_varying_unknown_reals=[\"observations\"],\n",
        "      time_varying_known_reals=[\"time_idx\"],\n",
        "      min_prediction_idx=training_cutoff+1,\n",
        "  )\n",
        "\n",
        "  return test\n",
        "\n",
        "\n",
        "def classify_obs(pid, pred, df, data_folder, size_of_pred, audio_ts, stimuli_type):\n",
        "  min_dist = float('inf')\n",
        "  most_similar = None\n",
        "\n",
        "  for filename in df[f'audio.{stimuli_type}']:\n",
        "    distance_dtw = dtw.distance_fast(pred, audio_ts[filename][-size_of_pred:].astype(np.double))\n",
        "\n",
        "    if distance_dtw < min_dist:\n",
        "      min_dist = distance_dtw\n",
        "      most_similar = filename\n",
        "    \n",
        "  return (pid, df[df[f'audio.{stimuli_type}'] == most_similar]['depression.symptoms'].iloc[0], min_dist)\n",
        "\n",
        "\n",
        "def classify_obs(pid, pred, df, data_folder, size_of_pred, audio_ts, stimuli_type):\n",
        "  min_dist = float('inf')\n",
        "  most_similar = None\n",
        "\n",
        "  for filename in df[f'audio.{stimuli_type}']:\n",
        "    distance_dtw = dtw.distance_fast(pred, audio_ts[filename][-size_of_pred:].astype(np.double))\n",
        "\n",
        "    if distance_dtw < min_dist:\n",
        "      min_dist = distance_dtw\n",
        "      most_similar = filename\n",
        "    \n",
        "  return (pid, df[df[f'audio.{stimuli_type}'] == most_similar]['depression.symptoms'].iloc[0], min_dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEJ6g6gynNS7"
      },
      "source": [
        "### Training the baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vxptssMNO7x"
      },
      "outputs": [],
      "source": [
        "# Fit first 4 observations\n",
        "files = train_df['audio.narrative'][:4]\n",
        "data_folder=os.path.join(DRIVE_PATH, 'wav files')\n",
        "\n",
        "new_df = load_and_preprocess(files, data_folder, min_len = 24)\n",
        "train_val = create_timeSeriesDataSet(new_df)\n",
        "\n",
        "train_dataloader = train_val[0].to_dataloader(\n",
        "    train=True, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        ")\n",
        "val_dataloader = train_val[1].to_dataloader(\n",
        "    train=False, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        ")\n",
        "\n",
        "# TemporalFusionTransformer model\n",
        "net = TemporalFusionTransformer.from_dataset(\n",
        "    train_val[0],\n",
        "    learning_rate=1e-3,\n",
        "    hidden_size = 16,\n",
        "    lstm_layers = 2,\n",
        "    dropout = 0.2,\n",
        "    attention_head_size = 4,\n",
        "    optimizer=\"AdamW\",\n",
        "    # optimizer=\"Ranger\",\n",
        "    loss=QuantileLoss(),\n",
        "    # log_interval=10,\n",
        ")\n",
        "net.to(device)\n",
        "\n",
        "# Trainer\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=2, verbose=False, mode=\"min\")\n",
        "lr_logger = LearningRateMonitor()  # log the learning rate\n",
        "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=2, #10 FOR NOW\n",
        "    accelerator=\"gpu\",\n",
        "    enable_model_summary=False,\n",
        "    gradient_clip_val=0.1,\n",
        "    limit_train_batches=2000,\n",
        "    callbacks=[lr_logger, early_stop_callback],\n",
        "    logger=logger,\n",
        "    enable_checkpointing=True,\n",
        "    check_val_every_n_epoch=1,\n",
        "    # reload_dataloaders_every_n_epochs = 10\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "  net,\n",
        "  train_dataloaders=train_dataloader,\n",
        "  val_dataloaders=val_dataloader,\n",
        ")\n",
        "\n",
        "# Fit for the rest observations\n",
        "for i in tqdm(range(4,len(train_df['audio.narrative']), 4)):\n",
        "  files = train_df['audio.narrative'][i:i+4]\n",
        "  data_folder=os.path.join(DRIVE_PATH, 'wav files')\n",
        "\n",
        "  new_df = load_and_preprocess(files, data_folder)\n",
        "\n",
        "  train_val = create_timeSeriesDataSet(new_df)\n",
        "\n",
        "  train_dataloader = train_val[0].to_dataloader(\n",
        "      train=True, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        "  )\n",
        "\n",
        "  val_dataloader = train_val[1].to_dataloader(\n",
        "      train=False, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        "  )\n",
        "\n",
        "  trainer = pl.Trainer(\n",
        "    max_epochs=2, #10 FOR NOW\n",
        "    accelerator=\"gpu\",\n",
        "    enable_model_summary=False,\n",
        "    gradient_clip_val=0.1,\n",
        "    limit_train_batches=2000,\n",
        "    callbacks=[early_stop_callback],\n",
        "    enable_checkpointing=True,\n",
        "    check_val_every_n_epoch=1,\n",
        "    # reload_dataloaders_every_n_epochs = 10\n",
        "  ) \n",
        "\n",
        "  trainer.fit(\n",
        "    net,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=val_dataloader,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_bKFwVQbPx3"
      },
      "outputs": [],
      "source": [
        "net1 = TemporalFusionTransformer.load_from_checkpoint(\"/content/lightning_logs/version_41/checkpoints/epoch=0-step=2000.ckpt\")\n",
        "net1.to(device)\n",
        "\n",
        "files = train_df['audio.narrative'][41*4:42*4]\n",
        "data_folder=os.path.join(DRIVE_PATH, 'wav files')\n",
        "\n",
        "new_df = load_and_preprocess(files, data_folder)\n",
        "train_val = create_timeSeriesDataSet(new_df)\n",
        "\n",
        "train_dataloader = train_val[0].to_dataloader(\n",
        "    train=True, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        ")\n",
        "val_dataloader = train_val[1].to_dataloader(\n",
        "    train=False, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=2, verbose=False, mode=\"min\")\n",
        "lr_logger = LearningRateMonitor()  # log the learning rate\n",
        "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=2, #10 FOR NOW\n",
        "    accelerator=\"gpu\",\n",
        "    enable_model_summary=False,\n",
        "    gradient_clip_val=0.1,\n",
        "    limit_train_batches=2000,\n",
        "    callbacks=[lr_logger, early_stop_callback],\n",
        "    logger=logger,\n",
        "    enable_checkpointing=True,\n",
        "    check_val_every_n_epoch=1,\n",
        "    # reload_dataloaders_every_n_epochs = 10\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "  net1,\n",
        "  train_dataloaders=train_dataloader,\n",
        "  val_dataloaders=val_dataloader,\n",
        ")\n",
        "\n",
        "\n",
        "# Fit for the rest observations\n",
        "for i in tqdm(range(4*42,len(train_df['audio.narrative']), 4)):\n",
        "  files = train_df['audio.narrative'][i:i+4]\n",
        "  data_folder=os.path.join(DRIVE_PATH, 'wav files')\n",
        "\n",
        "  new_df = load_and_preprocess(files, data_folder)\n",
        "\n",
        "  train_val = create_timeSeriesDataSet(new_df)\n",
        "\n",
        "  train_dataloader = train_val[0].to_dataloader(\n",
        "      train=True, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        "  )\n",
        "\n",
        "  val_dataloader = train_val[1].to_dataloader(\n",
        "      train=False, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        "  )\n",
        "\n",
        "  trainer = pl.Trainer(\n",
        "    max_epochs=2, #10 FOR NOW\n",
        "    accelerator=\"gpu\",\n",
        "    enable_model_summary=False,\n",
        "    gradient_clip_val=0.1,\n",
        "    limit_train_batches=2000,\n",
        "    callbacks=[early_stop_callback],\n",
        "    enable_checkpointing=True,\n",
        "    check_val_every_n_epoch=1,\n",
        "    # reload_dataloaders_every_n_epochs = 10\n",
        "  ) \n",
        "\n",
        "  trainer.fit(\n",
        "    net1,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=val_dataloader,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEaATURenRyK"
      },
      "source": [
        "### Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8ooxRCFtisM"
      },
      "outputs": [],
      "source": [
        "data_folder=os.path.join(DRIVE_PATH, 'wav files')\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "LIMIT_TRAIN_BATCHES = 1300\n",
        "EPOCHS = 2\n",
        "BASE_LEN_f = 5\n",
        "\n",
        "PREDICTION_LENGTH = 200\n",
        "CONTEXT_LENGTH = 200 \n",
        "LR = 5e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCt5rhSinT5Z"
      },
      "outputs": [],
      "source": [
        "def train_model(model, EPOCHS, stimuli_type):\n",
        "  # Fit for the rest observations\n",
        "  criterion = QuantileLoss()\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "  \n",
        "  for i in tqdm(range(0, len(train_df[f'audio.{stimuli_type}']), 4), desc='Files loaded'):\n",
        "    if (i+4 > len(train_df[f'audio.{stimuli_type}'])):\n",
        "      files = train_df[f'audio.{stimuli_type}'][i:]\n",
        "    else:\n",
        "      files = train_df[f'audio.{stimuli_type}'][i:i+4]\n",
        "    data_folder=os.path.join(DRIVE_PATH, 'wav files')\n",
        "\n",
        "    new_df = load_and_preprocess(files, data_folder, cutoff_len = BASE_LEN_f, min_len = BASE_LEN_f)\n",
        "    train_val = create_timeSeriesDataSet(new_df, prediction_len=PREDICTION_LENGTH, encoder_len=CONTEXT_LENGTH)\n",
        "\n",
        "    train_dataloader = train_val[0].to_dataloader(\n",
        "        train=True, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        "    )\n",
        "\n",
        "    val_dataloader = train_val[1].to_dataloader(\n",
        "        train=False, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        "    )\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "      model.train()\n",
        "      train_it = iter(train_dataloader)\n",
        "      train_loss = 0\n",
        "      for n_batches in range(LIMIT_TRAIN_BATCHES):\n",
        "        batch = next(train_it)\n",
        "        x = {k: v.to(device) for k, v in batch[0].items()}\n",
        "        y = batch[1][0].to(device)\n",
        "\n",
        "        out = model.forward(x)\n",
        "        loss = criterion(out['prediction'], target = y)\n",
        "        train_loss += loss.detach()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "      model.eval()\n",
        "      iteration = 0\n",
        "      overall_loss = 0\n",
        "      for val_batch in val_dataloader:\n",
        "        x_val = {k: v.to(device) for k, v in val_batch[0].items()}\n",
        "        y_val = val_batch[1][0].to(device)\n",
        "        out = model.forward(x_val)\n",
        "        loss = criterion(out['prediction'], target = y_val)\n",
        "        iteration += 1\n",
        "        overall_loss += loss.detach()\n",
        "\n",
        "      # print(f\"Epoch {epoch} Train loss: \", round(float(train_loss / LIMIT_TRAIN_BATCHES), 4), \"\\tVal loss: \",  round(float(overall_loss / iteration), 4))\n",
        "  return model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndbXZhHszLKa"
      },
      "outputs": [],
      "source": [
        "grid_v2 = { 'PREDICTION_CONTEXT_LENGTH': [[PREDICTION_LENGTH, CONTEXT_LENGTH]],\n",
        "        'hidden_size ' : [32, 64, 128],\n",
        "        'lstm_layers ' : [2, 4],\n",
        "        'attention_head_size ' : [4, 6],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7dab98ab82604954acf360cd0ab53928",
            "7bf22be3ac1646a3849686c2abaa4108",
            "2e38ac7d4f6c414386e24699df3b441e",
            "0c800ceeda1941ed9508f6cda43d97d4",
            "f5706edd67f149528a6b1809d0b7e3a5",
            "543600eeb2b3456aa9238938f1ece0a4",
            "79b4987158da4237aec4541c578d5e33",
            "87ac6d2900974002bb333623ab4b5e1a",
            "59c15db324ff4255ba71007bb9968f5d",
            "da70d11f1a6f403a9d99d0775554523b",
            "316760867fbd4404819db1ddfdecb2d2",
            "4d031ae33e824cf496a1be45dfbd9782",
            "23fb55274c454926906acf92f181d769",
            "6c4a1cd5514b4010811c3091ab45e001",
            "d5598e20878c4440bbb6738583e46d0c",
            "929c2d6228fa43c1a7b236dc2919680a",
            "45967371ff9941d58e5690d90265a0b9",
            "eef23b83b957465bbca6a81333bc7f16",
            "6c401ab46f174a008cd15db8928cece2",
            "c94e48e5b423498ba0f7a3c30b345472",
            "99b739b7c54a4981b380ac5699ee3237",
            "78a492ab1b4a48b189f428a7f73396c8"
          ]
        },
        "id": "dUHxTjFf0aq0",
        "outputId": "2a5b8818-8ce9-40b8-c02f-e8ccd52b3402"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dab98ab82604954acf360cd0ab53928",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Grid search progress:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d031ae33e824cf496a1be45dfbd9782",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Files loaded:   0%|          | 0/47 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from itertools import product\n",
        "\n",
        "tft_paths = \"/content/drive/MyDrive/Grid_search_thesis/TFT_models\"\n",
        "stimuli_type = 'narrative'\n",
        "# stimuli_type = 'story'\n",
        "# stimuli_type = 'instruction'\n",
        "\n",
        "for i, params in tqdm(enumerate(product(*grid_v2.values())), total = len(list(product(*grid_v2.values()))), desc='Grid search progress'):\n",
        "  if os.path.isfile(os.path.join(tft_paths, f'TFT_{stimuli_type}_{i}.pt')):\n",
        "    continue\n",
        "  \n",
        "  files = train_df[f'audio.{stimuli_type}'][:4]\n",
        "\n",
        "  new_df = load_and_preprocess(files, data_folder, cutoff_len = BASE_LEN_f, min_len = BASE_LEN_f)\n",
        "  train_val = create_timeSeriesDataSet(new_df, prediction_len=params[0][0], encoder_len=params[0][1])\n",
        "\n",
        "  # TFT model\n",
        "  net_tft = TemporalFusionTransformer.from_dataset(\n",
        "    train_val[0],\n",
        "    learning_rate=LR,\n",
        "    hidden_size = params[1],\n",
        "    lstm_layers = params[2],\n",
        "    attention_head_size = params[3],\n",
        "    dropout = 0.2,\n",
        "    output_size = 20\n",
        "  )\n",
        "  net_tft.to(device)\n",
        "\n",
        "  net_tft = train_model(net_tft, EPOCHS=EPOCHS, stimuli_type=stimuli_type)\n",
        "\n",
        "  torch.save({'model_state_dict' : net_tft.state_dict(),\n",
        "            'hyperparameters' : net_tft.hparams}, \n",
        "           os.path.join(tft_paths, f'TFT_{stimuli_type}_{i}.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMBO_YUPTbYM"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {
        "id": "awABOKfIGMb8"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "LIMIT_TRAIN_BATCHES = 300\n",
        "EPOCHS = 2\n",
        "BASE_LEN_f = 5\n",
        "\n",
        "PREDICTION_LENGTH = 200\n",
        "CONTEXT_LENGTH = 200 \n",
        "LR = 4e-3\n",
        "\n",
        "data_folder=os.path.join(DRIVE_PATH, 'wav files')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "menJOA08LGKB"
      },
      "outputs": [],
      "source": [
        "tft_paths = \"/content/drive/MyDrive/Grid_search_thesis/TFT_models\"\n",
        "tft_predictions_paths = '/content/drive/MyDrive/Grid_search_thesis/TFT_models/Predictions'\n",
        "\n",
        "# stimuli_type = 'narrative'\n",
        "# stimuli_type = 'story'\n",
        "stimuli_type = 'instruction'\n",
        "\n",
        "\n",
        "files = test_df[f'audio.{stimuli_type}']\n",
        "new_df = load_and_preprocess(files, data_folder, cutoff_len = BASE_LEN_f, min_len = BASE_LEN_f)\n",
        "test = create_timeSeriesDataSet_test(new_df, prediction_len=PREDICTION_LENGTH, encoder_len=CONTEXT_LENGTH)\n",
        "\n",
        "test_dataloader = test.to_dataloader(\n",
        "    train=False, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "fce216f8663443d1b5254465696090c9",
            "3578b943432f48438cd0d5a244f0cb38",
            "668ed72171f54ee486b0bb4fc872a543",
            "41fc62043bcd478899dff2eaf64bd2a3",
            "210fd17d0ae44c7389117992c753527f",
            "c96455c8757047269b9775f6057f2d35",
            "c4148af4663d4b5793656058aafcddb6",
            "b515da7beee1464fa3df8da5ce16b692",
            "c3649927bd734e6f98110d52798137e7",
            "5836a561b2e04c53a9b98f61e6765e98",
            "601b1a0492ab40278285856dc7183175"
          ]
        },
        "id": "H_6XvccnTc1k",
        "outputId": "d64ae07f-fa2a-49a3-9e53-d871cbf21e51"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fce216f8663443d1b5254465696090c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(12)):\n",
        "  checkpoint = torch.load(os.path.join(tft_paths, f'TFT_{stimuli_type}_{i}.pt'), map_location=torch.device(device))\n",
        "\n",
        "  # TFT model\n",
        "  net_tft = TemporalFusionTransformer.from_dataset(\n",
        "      test,\n",
        "      learning_rate=LR,\n",
        "      hidden_size = checkpoint['hyperparameters']['hidden_size'],\n",
        "      lstm_layers = checkpoint['hyperparameters']['lstm_layers'],\n",
        "      attention_head_size = checkpoint['hyperparameters']['attention_head_size'],\n",
        "      dropout = 0.2,\n",
        "      output_size = 20\n",
        "    )\n",
        "  net_tft.load_state_dict(checkpoint['model_state_dict'])\n",
        "  net_tft.to(device)\n",
        "\n",
        "\n",
        "  raw_predictions = net_tft.predict(\n",
        "    test_dataloader, mode=\"raw\",\n",
        "  )\n",
        "\n",
        "  predicted_classes = []\n",
        "  size_of_pred = raw_predictions[0].shape[1]\n",
        "  groups = new_df['group'].unique()\n",
        "\n",
        "  audio_ts = {}\n",
        "\n",
        "  for filename in train_df[f'audio.{stimuli_type}']:\n",
        "      signal, sr = lb.load(os.path.join(data_folder, filename), sr=SR)\n",
        "      signal, _ = lb.effects.trim(signal, top_db=35)\n",
        "      audio_ts[filename] = signal\n",
        "\n",
        "  for m in range(raw_predictions[0].size()[0]):\n",
        "    tmp = classify_obs(pid = groups[m], \n",
        "                      pred = raw_predictions[0][m].mean(axis=1).detach().cpu().numpy().astype(np.double),\n",
        "                      df = train_df, \n",
        "                      data_folder = data_folder,\n",
        "                      size_of_pred = size_of_pred,\n",
        "                      audio_ts = audio_ts,\n",
        "                      stimuli_type = stimuli_type)\n",
        "    predicted_classes.append(tmp)\n",
        "\n",
        "\n",
        "  pred_df = pd.DataFrame(predicted_classes, columns=['id', 'pred_severity', 'min_dist'])\n",
        "  pred_df['actual_severity'] = [test_df[test_df[f'audio.{stimuli_type}'] == j[3:]]['depression.symptoms'].iloc[0] for j in pred_df['id']]\n",
        "\n",
        "  pred_df.to_csv(os.path.join(tft_predictions_paths,f'TFT_{stimuli_type}_{i}_pred_multiple.csv'))\n",
        "  # pred_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmuqoQJzKOpm"
      },
      "source": [
        "### Best model for each type of stimuli"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Narrative: 8\n",
        "\n",
        "Story: 8\n",
        "\n",
        "Instruction: 0"
      ],
      "metadata": {
        "id": "UjWqLy7izRir"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "LO1nMMpe6GkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9612e088-7c44-420f-d04a-9cc85f178078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instruction 0 0.5007716049382716\n"
          ]
        }
      ],
      "source": [
        "import sklearn.metrics as skm \n",
        "\n",
        "tft_paths = \"/content/drive/MyDrive/Grid_search_thesis/TFT_models\"\n",
        "tft_predictions_paths = '/content/drive/MyDrive/Grid_search_thesis/TFT_models/Predictions'\n",
        "\n",
        "\n",
        "# stimuli_type = 'narrative'\n",
        "# stimuli_type = 'story'\n",
        "stimuli_type = 'instruction'\n",
        "\n",
        "best_score = 0\n",
        "model_n = 0\n",
        "\n",
        "for j in range(12):\n",
        "  predictions = pd.read_csv(os.path.join(tft_predictions_paths, f'TFT_{stimuli_type}_{j}_pred_multiple.csv'), index_col=0)\n",
        "  predictions['id'] = predictions['id'].apply(lambda x: x[3:])\n",
        "\n",
        "  # predictions[\"pred_severity\"].loc[(predictions['pred_severity'] == 2) | (predictions['pred_severity'] == 3)] = 1\n",
        "  # predictions['actual_severity'].loc[(predictions['actual_severity'] == 2) | (predictions['actual_severity'] == 3)] = 1\n",
        "  \n",
        "  best_guess = {}\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "    cnt = 1\n",
        "    if predictions['id'][i] not in best_guess:\n",
        "      best_guess[predictions['id'][i]] = [predictions['pred_severity'][i], predictions['min_dist'][i]]\n",
        "    elif best_guess[predictions['id'][i]][1] > predictions['min_dist'][i]:\n",
        "      best_guess[predictions['id'][i]] = [predictions['pred_severity'][i], predictions['min_dist'][i]]\n",
        "\n",
        "  tsdad = list(best_guess.keys())\n",
        "  tsdada = np.array(list(best_guess.values()))\n",
        "  tsdada[:, 0].astype(int)\n",
        "\n",
        "  single_pred = pd.DataFrame([tsdad, tsdada[:, 0].astype(int), tsdada[:, 1]]).T\n",
        "  single_pred.rename({0: 'id', 1 : 'pred_severity', 2 : 'DWT_dist'}, axis=1, inplace=True)\n",
        "  single_pred['actual_severity'] = [test_df[test_df[f'audio.{stimuli_type}'] == i]['depression.symptoms'].iloc[0] for i in single_pred['id']]\n",
        "  single_pred['pred_severity'] = single_pred['pred_severity'].astype(int)\n",
        "  report_nbeats = skm.classification_report(single_pred['actual_severity'], single_pred['pred_severity'], output_dict=True)\n",
        "\n",
        "  # maj_voting_pred = predictions.groupby(['id']).agg(lambda x:x.value_counts().index[0])\n",
        "  # report_nbeats = skm.classification_report(maj_voting_pred['actual_severity'], maj_voting_pred['pred_severity'], output_dict=True)\n",
        "\n",
        "  if report_nbeats['weighted avg']['f1-score'] > best_score:\n",
        "    model_n = j\n",
        "    best_score = report_nbeats['weighted avg']['f1-score']\n",
        "\n",
        "print(stimuli_type, model_n, best_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CV"
      ],
      "metadata": {
        "id": "iGKyiNlKS1AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "LIMIT_TRAIN_BATCHES = 3000\n",
        "EPOCHS = 2\n",
        "BASE_LEN_f = 5\n",
        "\n",
        "PREDICTION_LENGTH = 400\n",
        "CONTEXT_LENGTH = 800 \n",
        "LR = 3e-3\n",
        "\n",
        "data_folder=os.path.join(DRIVE_PATH, 'wav files')"
      ],
      "metadata": {
        "id": "cOxpKiIu_3SC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size = 0.1, train_size = 0.9, random_state = 42)\n",
        "cv_splits = {}\n",
        "\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(sss.split(df, df['depression.symptoms'])):\n",
        "  cv_splits[i] = (train_index, test_index)"
      ],
      "metadata": {
        "id": "zX7YYa7o9k8G"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tft_paths = \"/content/drive/MyDrive/Grid_search_thesis/TFT_models\"\n",
        "tft_predictions_paths = '/content/drive/MyDrive/Grid_search_thesis/TFT_models/Predictions'\n",
        "tft_cv = '/content/drive/MyDrive/Grid_search_thesis/TFT_models/CV_results' \n",
        "\n",
        "# stimuli_type = 'narrative'\n",
        "# stimuli_type = 'story'\n",
        "stimuli_type = 'instruction'\n",
        "\n",
        "checkpoint = torch.load(os.path.join(tft_paths, f'TFT_{stimuli_type}_{8}.pt'), map_location=torch.device(device))\n",
        "\n",
        "for i, idx in enumerate(cv_splits.values()):\n",
        "    # Obtain new train and test dataframes\n",
        "    train_df = df.iloc[idx[0]]\n",
        "    test_df = df.iloc[idx[1]]\n",
        "\n",
        "    files = train_df[f'audio.{stimuli_type}'][:4]\n",
        "    new_df = load_and_preprocess(files, data_folder, cutoff_len = BASE_LEN_f, min_len = BASE_LEN_f)\n",
        "    train_val = create_timeSeriesDataSet(new_df, prediction_len=PREDICTION_LENGTH, encoder_len=CONTEXT_LENGTH)\n",
        "\n",
        "    net_tft = TemporalFusionTransformer.from_dataset(\n",
        "      train_val[0],\n",
        "      learning_rate=LR,\n",
        "      hidden_size = checkpoint['hyperparameters']['hidden_size'],\n",
        "      lstm_layers = checkpoint['hyperparameters']['lstm_layers'],\n",
        "      attention_head_size = checkpoint['hyperparameters']['attention_head_size'],\n",
        "      dropout = 0.2,\n",
        "      output_size = 20\n",
        "    )\n",
        "    net_tft.load_state_dict(checkpoint['model_state_dict'])\n",
        "    net_tft.to(device)\n",
        "\n",
        "    net_tft = train_model(net_tft, EPOCHS=EPOCHS, stimuli_type=stimuli_type)\n",
        "\n",
        "    # Get predictions from it\n",
        "    files = test_df[f'audio.{stimuli_type}']\n",
        "    new_df = load_and_preprocess(files, data_folder, cutoff_len = BASE_LEN_f, min_len = BASE_LEN_f)\n",
        "    test = create_timeSeriesDataSet_test(new_df, prediction_len=PREDICTION_LENGTH, encoder_len=CONTEXT_LENGTH)\n",
        "\n",
        "    test_dataloader = test.to_dataloader(\n",
        "        train=False, batch_size=BATCH_SIZE, num_workers=0, batch_sampler=\"synchronized\"\n",
        "    )\n",
        "\n",
        "    raw_predictions = net_tft.predict(\n",
        "    test_dataloader, mode=\"raw\", return_x=True,\n",
        "    )\n",
        "\n",
        "    predicted_classes = []\n",
        "    size_of_pred = raw_predictions[0][0].shape[1]\n",
        "    groups = new_df['group'].unique()\n",
        "\n",
        "    audio_ts = {}\n",
        "\n",
        "    for filename in train_df[f'audio.{stimuli_type}']:\n",
        "        signal, sr = lb.load(os.path.join(data_folder, filename), sr=SR)\n",
        "        signal, _ = lb.effects.trim(signal, top_db=35)\n",
        "        audio_ts[filename] = signal\n",
        "\n",
        "    for m in range(len(raw_predictions[0][0])):\n",
        "      tmp = classify_obs(pid = groups[m], \n",
        "                        pred = raw_predictions[0][0][m].detach().cpu().numpy().astype(np.double),\n",
        "                        df = train_df, \n",
        "                        data_folder = data_folder,\n",
        "                        size_of_pred = size_of_pred,\n",
        "                        audio_ts = audio_ts,\n",
        "                        stimuli_type = stimuli_type)\n",
        "      predicted_classes.append(tmp)\n",
        "\n",
        "    pred_df = pd.DataFrame(predicted_classes, columns=['id', 'pred_severity', 'min_dist'])\n",
        "    pred_df['actual_severity'] = [test_df[test_df[f'audio.{stimuli_type}'] == j[3:]]['depression.symptoms'].iloc[0] for j in pred_df['id']]\n",
        "\n",
        "    pred_df['id'] = pred_df['id'].apply(lambda x: x[3:])\n",
        "\n",
        "    best_guess = {}\n",
        "\n",
        "    for i in range(len(pred_df)):\n",
        "      cnt = 1\n",
        "      if pred_df['id'][i] not in best_guess:\n",
        "        best_guess[pred_df['id'][i]] = [pred_df['pred_severity'][i], pred_df['min_dist'][i]]\n",
        "      elif best_guess[pred_df['id'][i]][1] > pred_df['min_dist'][i]:\n",
        "        best_guess[pred_df['id'][i]] = [pred_df['pred_severity'][i], pred_df['min_dist'][i]]\n",
        "\n",
        "    tsdad = list(best_guess.keys())\n",
        "    tsdada = np.array(list(best_guess.values()))\n",
        "    tsdada[:, 0].astype(int)\n",
        "\n",
        "    single_pred = pd.DataFrame([tsdad, tsdada[:, 0].astype(int), tsdada[:, 1]]).T\n",
        "    single_pred.rename({0: 'id', 1 : 'pred_severity', 2 : 'DWT_dist'}, axis=1, inplace=True)\n",
        "    single_pred['actual_severity'] = [test_df[test_df[f'audio.{stimuli_type}'] == i]['depression.symptoms'].iloc[0] for i in single_pred['id']]\n",
        "    single_pred['pred_severity'] = single_pred['pred_severity'].astype(int)\n",
        "    report_tft = skm.classification_report(single_pred['actual_severity'], single_pred['pred_severity'], output_dict=True)\n",
        "\n",
        "    single_pred.to_csv(os.path.join(tft_cv, f'TFT_{stimuli_type}_fold_{i}_pred.csv'))"
      ],
      "metadata": {
        "id": "b8cK5jcIS-vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0m86t9balKM"
      },
      "source": [
        "# **Playground**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tft_paths = \"/content/drive/MyDrive/Grid_search_thesis/TFT_models\"\n",
        "stimuli_type = 'narrative'\n",
        "# stimuli_type = 'story'\n",
        "# stimuli_type = 'instruction'\n",
        "\n",
        "\n",
        "checkpoint = torch.load(os.path.join(tft_paths, f'TFT_{stimuli_type}_{0}.pt'), map_location=torch.device(device))"
      ],
      "metadata": {
        "id": "f0nSx2i4QI1P"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint['hyperparameters']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gkfG_-yQgtk",
        "outputId": "e625574f-15af-4b50-ae13-16271635d7a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"attention_head_size\":               4\n",
              "\"categorical_groups\":                {}\n",
              "\"causal_attention\":                  True\n",
              "\"dropout\":                           0.2\n",
              "\"embedding_labels\":                  {}\n",
              "\"embedding_paddings\":                []\n",
              "\"embedding_sizes\":                   {}\n",
              "\"hidden_continuous_size\":            8\n",
              "\"hidden_continuous_sizes\":           {}\n",
              "\"hidden_size\":                       32\n",
              "\"learning_rate\":                     0.003\n",
              "\"log_gradient_flow\":                 False\n",
              "\"log_interval\":                      -1\n",
              "\"log_val_interval\":                  -1\n",
              "\"logging_metrics\":                   ModuleList(\n",
              "  (0): SMAPE()\n",
              "  (1): MAE()\n",
              "  (2): RMSE()\n",
              "  (3): MAPE()\n",
              ")\n",
              "\"loss\":                              QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98])\n",
              "\"lstm_layers\":                       2\n",
              "\"max_encoder_length\":                200\n",
              "\"monotone_constaints\":               {}\n",
              "\"optimizer\":                         Ranger\n",
              "\"optimizer_params\":                  None\n",
              "\"output_size\":                       20\n",
              "\"output_transformer\":                EncoderNormalizer(\n",
              "\tmethod='standard',\n",
              "\tcenter=True,\n",
              "\tmax_length=None,\n",
              "\ttransformation=None,\n",
              "\tmethod_kwargs={}\n",
              ")\n",
              "\"reduce_on_plateau_min_lr\":          1e-05\n",
              "\"reduce_on_plateau_patience\":        1000\n",
              "\"reduce_on_plateau_reduction\":       2.0\n",
              "\"share_single_variable_networks\":    False\n",
              "\"static_categoricals\":               []\n",
              "\"static_reals\":                      []\n",
              "\"time_varying_categoricals_decoder\": []\n",
              "\"time_varying_categoricals_encoder\": []\n",
              "\"time_varying_reals_decoder\":        ['time_idx']\n",
              "\"time_varying_reals_encoder\":        ['time_idx', 'observations']\n",
              "\"weight_decay\":                      0.0\n",
              "\"x_categoricals\":                    []\n",
              "\"x_reals\":                           ['time_idx', 'observations']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cEJ6g6gynNS7",
        "n0m86t9balKM",
        "PVVFQTrdMuuh",
        "UED71-KPPkjD",
        "E2raIt0lVCTf"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c800ceeda1941ed9508f6cda43d97d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da70d11f1a6f403a9d99d0775554523b",
            "placeholder": "​",
            "style": "IPY_MODEL_316760867fbd4404819db1ddfdecb2d2",
            "value": " 12/12 [2:40:24&lt;00:00, 802.01s/it]"
          }
        },
        "23fb55274c454926906acf92f181d769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45967371ff9941d58e5690d90265a0b9",
            "placeholder": "​",
            "style": "IPY_MODEL_eef23b83b957465bbca6a81333bc7f16",
            "value": "Files loaded: 100%"
          }
        },
        "2e38ac7d4f6c414386e24699df3b441e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ac6d2900974002bb333623ab4b5e1a",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59c15db324ff4255ba71007bb9968f5d",
            "value": 12
          }
        },
        "316760867fbd4404819db1ddfdecb2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45967371ff9941d58e5690d90265a0b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d031ae33e824cf496a1be45dfbd9782": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23fb55274c454926906acf92f181d769",
              "IPY_MODEL_6c4a1cd5514b4010811c3091ab45e001",
              "IPY_MODEL_d5598e20878c4440bbb6738583e46d0c"
            ],
            "layout": "IPY_MODEL_929c2d6228fa43c1a7b236dc2919680a"
          }
        },
        "543600eeb2b3456aa9238938f1ece0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c15db324ff4255ba71007bb9968f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c401ab46f174a008cd15db8928cece2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4a1cd5514b4010811c3091ab45e001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c401ab46f174a008cd15db8928cece2",
            "max": 47,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c94e48e5b423498ba0f7a3c30b345472",
            "value": 47
          }
        },
        "78a492ab1b4a48b189f428a7f73396c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79b4987158da4237aec4541c578d5e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bf22be3ac1646a3849686c2abaa4108": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_543600eeb2b3456aa9238938f1ece0a4",
            "placeholder": "​",
            "style": "IPY_MODEL_79b4987158da4237aec4541c578d5e33",
            "value": "Grid search progress: 100%"
          }
        },
        "7dab98ab82604954acf360cd0ab53928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bf22be3ac1646a3849686c2abaa4108",
              "IPY_MODEL_2e38ac7d4f6c414386e24699df3b441e",
              "IPY_MODEL_0c800ceeda1941ed9508f6cda43d97d4"
            ],
            "layout": "IPY_MODEL_f5706edd67f149528a6b1809d0b7e3a5"
          }
        },
        "87ac6d2900974002bb333623ab4b5e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929c2d6228fa43c1a7b236dc2919680a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99b739b7c54a4981b380ac5699ee3237": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94e48e5b423498ba0f7a3c30b345472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5598e20878c4440bbb6738583e46d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b739b7c54a4981b380ac5699ee3237",
            "placeholder": "​",
            "style": "IPY_MODEL_78a492ab1b4a48b189f428a7f73396c8",
            "value": " 47/47 [2:40:13&lt;00:00, 201.73s/it]"
          }
        },
        "da70d11f1a6f403a9d99d0775554523b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef23b83b957465bbca6a81333bc7f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5706edd67f149528a6b1809d0b7e3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce216f8663443d1b5254465696090c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3578b943432f48438cd0d5a244f0cb38",
              "IPY_MODEL_668ed72171f54ee486b0bb4fc872a543",
              "IPY_MODEL_41fc62043bcd478899dff2eaf64bd2a3"
            ],
            "layout": "IPY_MODEL_210fd17d0ae44c7389117992c753527f"
          }
        },
        "3578b943432f48438cd0d5a244f0cb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c96455c8757047269b9775f6057f2d35",
            "placeholder": "​",
            "style": "IPY_MODEL_c4148af4663d4b5793656058aafcddb6",
            "value": "100%"
          }
        },
        "668ed72171f54ee486b0bb4fc872a543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b515da7beee1464fa3df8da5ce16b692",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3649927bd734e6f98110d52798137e7",
            "value": 2
          }
        },
        "41fc62043bcd478899dff2eaf64bd2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5836a561b2e04c53a9b98f61e6765e98",
            "placeholder": "​",
            "style": "IPY_MODEL_601b1a0492ab40278285856dc7183175",
            "value": " 2/2 [04:31&lt;00:00, 133.82s/it]"
          }
        },
        "210fd17d0ae44c7389117992c753527f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96455c8757047269b9775f6057f2d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4148af4663d4b5793656058aafcddb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b515da7beee1464fa3df8da5ce16b692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3649927bd734e6f98110d52798137e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5836a561b2e04c53a9b98f61e6765e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601b1a0492ab40278285856dc7183175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}